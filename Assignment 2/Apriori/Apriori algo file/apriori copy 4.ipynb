{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import chain, combinations\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import csv\n",
    "import ast\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Reading and Processing CSV Files one at a time\n",
    "def read_transactions(csv_folder):\n",
    "    for filename in os.listdir(csv_folder):\n",
    "        if filename.endswith('.csv'):\n",
    "            with open(f\"{csv_folder}/{filename}\") as file:\n",
    "                csvreader = csv.reader(file)\n",
    "                csv.field_size_limit(1000000)\n",
    "                transactions = [ast.literal_eval(row[0]) for row in csvreader]\n",
    "                yield transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_unique_items(csv_folder):\n",
    "    unique_items = set()\n",
    "    for transactions in read_transactions(csv_folder):\n",
    "        for transaction in transactions:\n",
    "            unique_items.update(transaction)\n",
    "    return unique_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Candidate Generation\n",
    "def generate_candidate_itemsets(unique_items):\n",
    "    return set([(item,) for item in unique_items])\n",
    "\n",
    "def generate_candidate_itemsets_from_previous(frequent_itemsets, size):\n",
    "    all_items = set()\n",
    "    for itemset in frequent_itemsets:\n",
    "        all_items.update(itemset)\n",
    "    return set(combinations(all_items, size))\n",
    "\n",
    "# Step 3: Support Calculation\n",
    "def calculate_support(transactions, candidates):\n",
    "    candidate_counts = defaultdict(int)\n",
    "    for transaction in transactions:\n",
    "        for candidate in candidates:\n",
    "            if set(candidate).issubset(transaction):\n",
    "                candidate_counts[candidate] += 1\n",
    "    return candidate_counts\n",
    "\n",
    "# Step 4: Pruning Candidates\n",
    "def prune_candidates(candidate_counts, total_transactions, min_support):\n",
    "    pruned_itemsets = {}\n",
    "    for candidate, count in candidate_counts.items():\n",
    "        support = count / total_transactions\n",
    "        if support >= min_support:\n",
    "            pruned_itemsets[candidate] = support\n",
    "\n",
    "    return pruned_itemsets\n",
    "\n",
    "# Step 5: Saving the Frequent Itemsets\n",
    "def save_frequent_itemsets_csv(frequent_itemsets, output_file):\n",
    "    # Convert the frequent itemsets dictionary into a list of tuples\n",
    "    itemsets_list = [(list(itemset), support) for itemset, support in frequent_itemsets.items()]\n",
    "\n",
    "    # Create a DataFrame from this list\n",
    "    itemsets_df = pd.DataFrame(itemsets_list, columns=['Itemset', 'Support'])\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    itemsets_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Items: {'Bills and Utilities', 'Tax', 'Entertainment', 'Health', 'Clothing', 'Education', 'Fines', 'Gambling', 'Motor/Travel', 'Housing', 'Savings', 'Groceries'}\n",
      "== Generating 1 Itemsets ==\n",
      "Candidate Itemsets for k=1: {('Housing',), ('Education',), ('Fines',), ('Bills and Utilities',), ('Clothing',), ('Groceries',), ('Gambling',), ('Entertainment',), ('Health',), ('Motor/Travel',), ('Savings',), ('Tax',)}\n",
      "== 1 Frequent Itemsets generated ==\n",
      "== Calculating support for k=1 ==\n",
      "== Calculated support ==\n",
      "== Finished 1 Frequent Itemsets ==\n",
      "== Generating 2 Itemsets ==\n",
      "Candidate Itemsets for k=2: {('Bills and Utilities', 'Clothing'), ('Clothing', 'Gambling'), ('Housing', 'Savings'), ('Bills and Utilities', 'Fines'), ('Bills and Utilities', 'Health'), ('Fines', 'Savings'), ('Bills and Utilities', 'Entertainment'), ('Entertainment', 'Groceries'), ('Education', 'Gambling'), ('Bills and Utilities', 'Savings'), ('Motor/Travel', 'Savings'), ('Health', 'Gambling'), ('Gambling', 'Motor/Travel'), ('Bills and Utilities', 'Housing'), ('Fines', 'Housing'), ('Motor/Travel', 'Housing'), ('Housing', 'Groceries'), ('Tax', 'Motor/Travel'), ('Clothing', 'Motor/Travel'), ('Entertainment', 'Gambling'), ('Tax', 'Education'), ('Savings', 'Groceries'), ('Tax', 'Fines'), ('Bills and Utilities', 'Groceries'), ('Fines', 'Groceries'), ('Motor/Travel', 'Groceries'), ('Tax', 'Clothing'), ('Clothing', 'Education'), ('Bills and Utilities', 'Tax'), ('Clothing', 'Fines'), ('Education', 'Motor/Travel'), ('Tax', 'Health'), ('Gambling', 'Savings'), ('Health', 'Motor/Travel'), ('Tax', 'Entertainment'), ('Clothing', 'Entertainment'), ('Clothing', 'Health'), ('Fines', 'Gambling'), ('Health', 'Education'), ('Tax', 'Savings'), ('Clothing', 'Savings'), ('Education', 'Fines'), ('Gambling', 'Housing'), ('Bills and Utilities', 'Gambling'), ('Tax', 'Housing'), ('Clothing', 'Housing'), ('Entertainment', 'Motor/Travel'), ('Health', 'Fines'), ('Education', 'Savings'), ('Gambling', 'Groceries'), ('Health', 'Savings'), ('Entertainment', 'Education'), ('Entertainment', 'Fines'), ('Tax', 'Groceries'), ('Clothing', 'Groceries'), ('Health', 'Housing'), ('Education', 'Housing'), ('Entertainment', 'Health'), ('Entertainment', 'Savings'), ('Bills and Utilities', 'Motor/Travel'), ('Fines', 'Motor/Travel'), ('Education', 'Groceries'), ('Entertainment', 'Housing'), ('Bills and Utilities', 'Education'), ('Health', 'Groceries'), ('Tax', 'Gambling')}\n",
      "== 2 Frequent Itemsets generated ==\n",
      "== Calculating support for k=2 ==\n",
      "== Calculated support ==\n",
      "== Finished 2 Frequent Itemsets ==\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Main Apriori Function\n",
    "def apriori(csv_folder, max_length, min_support, output_file):\n",
    "    all_unique_items = collect_all_unique_items(csv_folder)\n",
    "    print(f'Unique Items: {all_unique_items}')\n",
    "    all_frequent_itemsets = {}\n",
    "\n",
    "    for k in range(1, max_length + 1):\n",
    "        \n",
    "        print(f\"== Generating {k} Itemsets ==\")\n",
    "        if k == 1:\n",
    "            candidate_itemsets = generate_candidate_itemsets(all_unique_items)\n",
    "        else:\n",
    "            candidate_itemsets = generate_candidate_itemsets_from_previous(all_frequent_itemsets, k)\n",
    "        print(f'Candidate Itemsets for k={k}: {candidate_itemsets}')\n",
    "        print(f\"== {k} Frequent Itemsets generated ==\")\n",
    "\n",
    "        candidate_counts = defaultdict(int)\n",
    "        total_transactions = 0\n",
    "\n",
    "        print(f\"== Calculating support for k={k} ==\")\n",
    "        for transactions in read_transactions(csv_folder):\n",
    "            local_counts = calculate_support(transactions, candidate_itemsets)  \n",
    "            for candidate, count in local_counts.items():\n",
    "                candidate_counts[candidate] += count\n",
    "            total_transactions += len(transactions)\n",
    "\n",
    "        # Calculate global support and prune\n",
    "        frequent_itemsets =  prune_candidates(candidate_counts, total_transactions, min_support)\n",
    "\n",
    "        print(f\"== Calculated support ==\")\n",
    "        \n",
    "        if not frequent_itemsets:\n",
    "            break\n",
    "\n",
    "        all_frequent_itemsets.update(frequent_itemsets)\n",
    "        print(f\"== Finished {k} Frequent Itemsets ==\")\n",
    "\n",
    "    save_frequent_itemsets_csv(all_frequent_itemsets, output_file)\n",
    "    return all_frequent_itemsets\n",
    "\n",
    "# Run the Apriori algorithm\n",
    "max_length = 2\n",
    "min_support = 0.01\n",
    "\n",
    "final_frequent_itemsets = apriori(\n",
    "    csv_folder='../Dataset/transactions_split_chunks/', #EDIT THIS TO YOUR CHUNK FOLDER\n",
    "    max_length=max_length, \n",
    "    min_support=min_support, \n",
    "    output_file=f'../Frequent Itemsets/transactions_{min_support}_{max_length}.csv',\n",
    ")\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
